{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data is : (307511, 122)\n"
     ]
    }
   ],
   "source": [
    "#reading loan data\n",
    "input_loan_data = pd.read_csv(\"housing_loan_data.csv\")\n",
    "print(\"Shape of input data is :\", input_loan_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Shape of input data is : (8602, 122)\n"
     ]
    }
   ],
   "source": [
    "#fill NAN rows\n",
    "input_na_rows_filled = input_loan_data.dropna()\n",
    "print(input_na_rows_filled.isnull().values.any())\n",
    "print(\"Shape of input data is :\", input_na_rows_filled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data is : (8602, 122)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#check if there are still any NAN rows\n",
    "non_null_data = input_na_rows_filled.notnull()\n",
    "print(\"Shape of input data is :\", non_null_data.shape)\n",
    "print(input_na_rows_filled.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of payers is  526  number of defaulters is  8076\n",
      "Proportion of defaulters to payers: 15.35 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVnUlEQVR4nO3dbbBd1X3f8e8vKBA/pEjAjYolOaJBtgMvTKgG8LgPrpUIgdOITm2K69YKVaJMi9vYbWPjdFq1tmkgzYSacUOiBKWyxzWmJB5Um5jKst024/AgbEoMmOoagyWZh2sk8AM2CfjfF2cJH8v36p4LV+eC1vczc+bs/V9r77M2I35n333WOTtVhSSpDz+y0AOQJI2PoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YujreS3Jt4Ye30vynaH1t4xpDK9LsneEfmcluTHJY0n2J7k1ycVjGN9nk/zSkX4dHR0MfT2vVdVLDz6ArwJ/d6j24VH2kWTRkR0lJHkN8GngfwGnAicC/xQ470i/tjQXhr5ekNpZ9Z+1s+oHk3wgybFD7ZXkkiS7gd2t9s7W92tJfqn1ObW1HZfkt5J8NcnDSX43yYuSvAT4E+BlQ39hvGyaIf0nYFtVXVFVX6+B26vqwqEx/XKSyfZXwPaD+0myso1l0VDfZ87ek/xikj9t4zuQ5CtJzmttlwF/E/hAG9sH5vk/tY4yhr5eqJ4G3gGcBLwGWAP8s0P6XACcDZyWZB3wL4GfZXAm/rpD+l4OvAI4o7UvA/5dVX2bwdn614b+wvja8IZJXtzGcP1Mg03yeuA3gAuBk4EHgGvncLxnA/e24/1N4Jokqap/A/wf4G1tbG+bwz7VIUNfL0jtLPrmqnqqqu4Hfg/424d0+42q2l9V32EQtn9YVXdV1RPAvz/YKUmATcA7Wv9vAv8RuGjE4Sxh8P/Sg4fp8xZga1V9vqqeBN4NvCbJyhFf44Gq+v2qehrYxuCNY+mI20rPOOLXOqUjIckrgN8GVgMvZvBv+fZDuu0ZWn4ZsGuGtom2j9sH+T94CeCYEYdzAPgegyD+0gx9XgZ8/uBKVX0ryaMM/qLYN8JrPDS07RNtnC8dcXzSMzzT1wvV1QwCdlVV/RXg1xkE9bDhn5B9EFg+tL5iaPnrwHeA06tqcXsc3z48PnQ/P6T95fBnwN8/TLevAT95cKV9VnAig8D/diu/eKj/Xz3cax46hDn0VecMfb1Q/TjwDeBbSV7FYKbM4VwHXJzkp9s1+H97sKGqvgf8PnBlkp8ASLIsybmty8PAiUmOP8z+3wn8YpJfS3Ji28erkxy8bv+R9vpnJDmOweWjW6rq/qqaYhD+/yjJMUn+CfBTI/+XGIzvr82hvzpm6OuF6l8D/xD4JoPA/ujhOlfVnwBXAZ8BJoGbW9OT7fldB+tJvgF8Cnhl2/ZLDEL7vjZb6Idm71TV54DXt8d9SfYDW4AbW/unGLzR/BGDvzp+ih/8zOCXgV8DHgVOBz434n8HgPcDb2wze66aw3bqULyJinqU5KeBLwLHVdVTCz0eaVw801c3kvy9Nh9/CXAF8D8MfPXG0FdPfgV4BPgyg3n+s30OIB11vLwjSR3xTF+SOmLoS1JHntffyD3ppJNq5cqVCz0MSXpBuf32279eVRPTtT2vQ3/lypXs2rVr9o6SpGckeWCmNi/vSFJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkZFCP8k7ktyV5ItJPpLkx5KckuSWJJNJPprk2Nb3uLY+2dpXDu3n3a1+79ANKiRJYzLrl7OSLAP+BXBaVX0nyXUMbv5wPnBlVV2b5HeBjQxuYbcROFBVpya5iMFP2P6DJKe17U5ncL/QTyV5RbvR8wvayks/sdBDOKrcf/kbFnoI0lFr1Ms7i4AXJVnE4D6eDzK4Q9D1rX0bcEFbXt/Wae1rMriL83rg2qp6sqq+wuAuRWc95yOQJI1s1tCvqn3AbwFfZRD2jwO3A48N3YBiL7CsLS8D9rRtn2r9TxyuT7PNM5JsSrIrya6pqalnc0ySpBnMGvrtLkPrgVMYXJZ5CbDuSA2oqrZU1eqqWj0xMe3vBUmSnqVRLu/8LPCVqpqqqr8E/hh4LbC4Xe4BWA7sa8v7gBUArf14Bjd7fqY+zTaSpDEYJfS/CpyT5MXt2vwa4G7gM8AbW58NwA1teXtbp7V/uga359oOXNRm95wCrAJunZ/DkCSNYtbZO1V1S5Lrgc8DTwFfALYAnwCuTfK+VrumbXIN8KEkk8B+BjN2qKq72syfu9t+LjkaZu5I0gvJSL+nX1Wbgc2HlO9jmtk3VfVd4E0z7Ocy4LI5jlGSNE/8Rq4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOj3Bj9lUnuGHp8I8nbk5yQZEeS3e15SeufJFclmUxyZ5Izh/a1ofXfnWTDzK8qSToSZg39qrq3qs6oqjOAvw48AXwMuBTYWVWrgJ1tHeA8Bve/XQVsAq4GSHICg7tvnc3gjlubD75RSJLGY66Xd9YAX66qB4D1wLZW3wZc0JbXAx+sgZuBxUlOBs4FdlTV/qo6AOwA1j3XA5AkjW6uoX8R8JG2vLSqHmzLDwFL2/IyYM/QNntbbaa6JGlMRg79JMcCvwD890PbqqqAmo8BJdmUZFeSXVNTU/OxS0lSM5cz/fOAz1fVw2394XbZhvb8SKvvA1YMbbe81Waq/4Cq2lJVq6tq9cTExByGJ0mazVxC/818/9IOwHbg4AycDcANQ/W3tlk85wCPt8tANwFrkyxpH+CubTVJ0pgsGqVTkpcAPwf8ylD5cuC6JBuBB4ALW/1G4HxgksFMn4sBqmp/kvcCt7V+76mq/c/5CCRJIxsp9Kvq28CJh9QeZTCb59C+BVwyw362AlvnPkxJ0nzwG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkZFCP8niJNcn+VKSe5K8JskJSXYk2d2el7S+SXJVkskkdyY5c2g/G1r/3Uk2zPyKkqQjYdQz/fcDn6yqVwGvBu4BLgV2VtUqYGdbBzgPWNUem4CrAZKcAGwGzgbOAjYffKOQJI3HrKGf5HjgbwHXAFTVX1TVY8B6YFvrtg24oC2vBz5YAzcDi5OcDJwL7Kiq/VV1ANgBrJvHY5EkzWKUM/1TgCngD5N8IckfJHkJsLSqHmx9HgKWtuVlwJ6h7fe22kx1SdKYjBL6i4Azgaur6meAb/P9SzkAVFUBNR8DSrIpya4ku6ampuZjl5KkZpTQ3wvsrapb2vr1DN4EHm6XbWjPj7T2fcCKoe2Xt9pM9R9QVVuqanVVrZ6YmJjLsUiSZjFr6FfVQ8CeJK9spTXA3cB24OAMnA3ADW15O/DWNovnHODxdhnoJmBtkiXtA9y1rSZJGpNFI/b758CHkxwL3AdczOAN47okG4EHgAtb3xuB84FJ4InWl6ran+S9wG2t33uqav+8HIUkaSQjhX5V3QGsnqZpzTR9C7hkhv1sBbbOYXySpHnkN3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0ZKfST3J/kz5PckWRXq52QZEeS3e15SasnyVVJJpPcmeTMof1saP13J9kw0+tJko6MuZzp/52qOqOqDt5B61JgZ1WtAna2dYDzgFXtsQm4GgZvEsBm4GzgLGDzwTcKSdJ4PJfLO+uBbW15G3DBUP2DNXAzsDjJycC5wI6q2l9VB4AdwLrn8PqSpDkaNfQL+J9Jbk+yqdWWVtWDbfkhYGlbXgbsGdp2b6vNVJckjclIN0YH/kZV7UvyE8COJF8abqyqSlLzMaD2prIJ4OUvf/l87FKS1Ix0pl9V+9rzI8DHGFyTf7hdtqE9P9K67wNWDG2+vNVmqh/6WluqanVVrZ6YmJjb0UiSDmvW0E/ykiQ/fnAZWAt8EdgOHJyBswG4oS1vB97aZvGcAzzeLgPdBKxNsqR9gLu21SRJYzLK5Z2lwMeSHOz/36rqk0luA65LshF4ALiw9b8ROB+YBJ4ALgaoqv1J3gvc1vq9p6r2z9uRSJJmNWvoV9V9wKunqT8KrJmmXsAlM+xrK7B17sOUJM0Hv5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHRk59JMck+QLST7e1k9JckuSySQfTXJsqx/X1idb+8qhfby71e9Ncu68H40k6bDmcqb/q8A9Q+tXAFdW1anAAWBjq28EDrT6la0fSU4DLgJOB9YBv5PkmOc2fEnSXIwU+kmWA28A/qCtB3g9cH3rsg24oC2vb+u09jWt/3rg2qp6sqq+wuDG6WfNwzFIkkY06pn+fwbeCXyvrZ8IPFZVT7X1vcCytrwM2APQ2h9v/Z+pT7ONJGkMZg39JD8PPFJVt49hPCTZlGRXkl1TU1PjeElJ6sYoZ/qvBX4hyf3AtQwu67wfWJxkUeuzHNjXlvcBKwBa+/HAo8P1abZ5RlVtqarVVbV6YmJizgckSZrZrKFfVe+uquVVtZLBB7Gfrqq3AJ8B3ti6bQBuaMvb2zqt/dNVVa1+UZvdcwqwCrh13o5EkjSrRbN3mdG7gGuTvA/4AnBNq18DfCjJJLCfwRsFVXVXkuuAu4GngEuq6unn8PqSpDmaU+hX1WeBz7bl+5hm9k1VfRd40wzbXwZcNtdBSpLmh9/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI7MGvpJfizJrUn+b5K7kvyHVj8lyS1JJpN8NMmxrX5cW59s7SuH9vXuVr83yblH7KgkSdMa5Uz/SeD1VfVq4AxgXZJzgCuAK6vqVOAAsLH13wgcaPUrWz+SnMbgfrmnA+uA30lyzDweiyRpFrOGfg18q63+aHsU8Hrg+lbfBlzQlte3dVr7miRp9Wur6smq+gowyTT32JUkHTkjXdNPckySO4BHgB3Al4HHquqp1mUvsKwtLwP2ALT2x4ETh+vTbDP8WpuS7Eqya2pqas4HJEma2UihX1VPV9UZwHIGZ+evOlIDqqotVbW6qlZPTEwcqZeRpC7NafZOVT0GfAZ4DbA4yaLWtBzY15b3ASsAWvvxwKPD9Wm2kSSNwSizdyaSLG7LLwJ+DriHQfi/sXXbANzQlre3dVr7p6uqWv2iNrvnFGAVcOs8HYckaQSLZu/CycC2NtPmR4DrqurjSe4Grk3yPuALwDWt/zXAh5JMAvsZzNihqu5Kch1wN/AUcElVPT2/hyNJOpxZQ7+q7gR+Zpr6fUwz+6aqvgu8aYZ9XQZcNvdhSpLmg9/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZJTbJa5I8pkkdye5K8mvtvoJSXYk2d2el7R6klyVZDLJnUnOHNrXhtZ/d5INM72mJOnIGOVM/yngX1XVacA5wCVJTgMuBXZW1SpgZ1sHOI/B/W9XAZuAq2HwJgFsBs5mcMetzQffKCRJ4zFr6FfVg1X1+bb8TQY3RV8GrAe2tW7bgAva8nrggzVwM7A4ycnAucCOqtpfVQeAHcC6+TwYSdLhzemafpKVDO6XewuwtKoebE0PAUvb8jJgz9Bme1ttprokaUxGDv0kLwX+CHh7VX1juK2qCqj5GFCSTUl2Jdk1NTU1H7uUJDUjhX6SH2UQ+B+uqj9u5YfbZRva8yOtvg9YMbT58labqf4DqmpLVa2uqtUTExNzORZJ0ixGmb0T4Brgnqr67aGm7cDBGTgbgBuG6m9ts3jOAR5vl4FuAtYmWdI+wF3bapKkMVk0Qp/XAv8Y+PMkd7TarwOXA9cl2Qg8AFzY2m4EzgcmgSeAiwGqan+S9wK3tX7vqar983EQkqTRzBr6VfWnQGZoXjNN/wIumWFfW4GtcxmgJGn++I1cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sgo98jdmuSRJF8cqp2QZEeS3e15SasnyVVJJpPcmeTMoW02tP67k2yY7rUkSUfWKGf6/xVYd0jtUmBnVa0CdrZ1gPOAVe2xCbgaBm8SwGbgbOAsYPPBNwpJ0vjMGvpV9b+BQ29gvh7Y1pa3ARcM1T9YAzcDi5OcDJwL7Kiq/VV1ANjBD7+RSJKOsGd7TX9pVT3Ylh8ClrblZcCeoX57W22muiRpjJ7zB7lVVUDNw1gASLIpya4ku6ampuZrt5Iknn3oP9wu29CeH2n1fcCKoX7LW22m+g+pqi1VtbqqVk9MTDzL4UmSpvNsQ387cHAGzgbghqH6W9ssnnOAx9tloJuAtUmWtA9w17aaJGmMFs3WIclHgNcBJyXZy2AWzuXAdUk2Ag8AF7buNwLnA5PAE8DFAFW1P8l7gdtav/dU1aEfDkuSjrBZQ7+q3jxD05pp+hZwyQz72QpsndPoJEnzym/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkVnn6Ut6YVt56ScWeghHjfsvf8NCD+E580xfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MvbQT7Iuyb1JJpNcOu7Xl6SejTX0kxwD/BfgPOA04M1JThvnGCSpZ+M+0z8LmKyq+6rqL4BrgfVjHoMkdWvcP7i2DNgztL4XOHu4Q5JNwKa2+q0k945pbD04Cfj6Qg9iNrlioUegBeC/zfn1kzM1PO9+ZbOqtgBbFnocR6Mku6pq9UKPQzqU/zbHZ9yXd/YBK4bWl7eaJGkMxh36twGrkpyS5FjgImD7mMcgSd0a6+WdqnoqyduAm4BjgK1Vddc4x9A5L5vp+cp/m2OSqlroMUiSxsRv5EpSRwx9SeqIoS9JHXnezdPX/EnyKgbfeF7WSvuA7VV1z8KNStJC8kz/KJXkXQx+5iLAre0R4CP+0J2ez5JcvNBjOJo5e+coleT/AadX1V8eUj8WuKuqVi3MyKTDS/LVqnr5Qo/jaOXlnaPX94CXAQ8cUj+5tUkLJsmdMzUBS8c5lt4Y+kevtwM7k+zm+z9y93LgVOBtCzUoqVkKnAscOKQe4HPjH04/DP2jVFV9MskrGPyc9fAHubdV1dMLNzIJgI8DL62qOw5tSPLZsY+mI17Tl6SOOHtHkjpi6EtSRwx9SeqIoS9JHTH0Jakj/x/9Ykifxe5mCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check for imbalanced data\n",
    "target_column = input_na_rows_filled[\"TARGET\"]\n",
    "target_count = target_column.value_counts()\n",
    "print(\"number of payers is \", target_count[1], \" number of defaulters is \", target_count[0])\n",
    "print('Proportion of defaulters to payers:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "target_count.plot(kind='bar', title='Target Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "SK_ID_CURR                      int64\n",
      "TARGET                          int64\n",
      "NAME_CONTRACT_TYPE              int64\n",
      "CODE_GENDER                     int64\n",
      "FLAG_OWN_CAR                    int64\n",
      "                               ...   \n",
      "AMT_REQ_CREDIT_BUREAU_DAY     float64\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK    float64\n",
      "AMT_REQ_CREDIT_BUREAU_MON     float64\n",
      "AMT_REQ_CREDIT_BUREAU_QRT     float64\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR    float64\n",
      "Length: 122, dtype: object\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Encoding string columns to int columns\n",
    "print(input_na_rows_filled.isnull().values.any())\n",
    "\n",
    "for columns in input_na_rows_filled.columns:\n",
    "    if (input_na_rows_filled[columns].dtype == \"object\"):\n",
    "        (input_na_rows_filled[columns], uniques) = pd.factorize(input_na_rows_filled[columns])\n",
    "\n",
    "print(input_na_rows_filled.dtypes)\n",
    "print(input_na_rows_filled.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data size is  (8602, 121)  Y_data size is  (8602, 1)\n",
      "Shape of X_ros is  (16152, 121) Shape of Y_ros is  (16152,)\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#dividing X and Y in data\n",
    "X = np.array(input_na_rows_filled.iloc[:, input_na_rows_filled.columns != 'TARGET'])\n",
    "Y = np.array(input_na_rows_filled.iloc[:, input_na_rows_filled.columns == 'TARGET'])\n",
    "print(\"X_data size is \", X.shape, \" Y_data size is \", Y.shape)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_normalized = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized)\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros, Y_ros = ros.fit_sample(X, Y)\n",
    "print(\"Shape of X_ros is \", X_ros.shape, \"Shape of Y_ros is \", Y_ros.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_after_oversampling = pd.Series(Y_ros).value_counts()\n",
    "count_after_oversampling.plot(kind='bar', title='Target Count');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              0         1         2         3         4         5         6   \\\n",
      "0     -0.171180 -0.260412 -0.268841 -0.431088  0.598883 -0.190181  0.005954   \n",
      "1     -0.594137  0.042454 -0.576920  0.207156 -0.030022  0.048092 -0.072956   \n",
      "2      1.593672  1.225180 -0.770527  0.235978  0.740256  1.194938  1.121259   \n",
      "3      0.382142  0.951398  0.330425 -0.668058  0.748926  0.119200  0.284713   \n",
      "4      0.554821  0.549595  0.173732 -0.294433  1.282695  0.760384 -0.586854   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "16147 -0.257189 -0.271818 -0.279205 -0.379871  0.435894 -0.223419 -0.079122   \n",
      "16148 -0.180649 -0.188993  0.277503 -0.680475  0.303527  0.601707 -0.139564   \n",
      "16149 -0.460450 -0.240145  0.208532 -0.644674 -0.115283 -0.864159  0.400857   \n",
      "16150 -0.592130  0.035001 -0.551037  0.163148  0.017281  0.092034  0.146167   \n",
      "16151  0.756556 -0.862850 -0.477737 -0.133231 -0.347893 -0.158502 -0.084231   \n",
      "\n",
      "             7         8         9   ...        90        91        92  \\\n",
      "0     -0.312869 -0.135602 -0.114606  ...  0.000657 -0.000853 -0.000353   \n",
      "1     -0.196374  0.039976 -0.170363  ...  0.000880  0.000277  0.000274   \n",
      "2      0.190480 -0.388660  0.017595  ...  0.011376  0.002354 -0.002989   \n",
      "3      0.494277 -0.502542 -0.356159  ... -0.000436 -0.000984 -0.000798   \n",
      "4     -0.105995  0.238075 -0.048543  ...  0.010318 -0.001994  0.000923   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "16147 -0.144597  0.009630 -0.102682  ... -0.002421  0.001952 -0.000942   \n",
      "16148  0.162125  0.582807 -0.229752  ... -0.006545  0.002520 -0.002275   \n",
      "16149  0.446208 -0.249966 -0.324418  ...  0.006536 -0.002048 -0.000349   \n",
      "16150 -0.011264  0.122768 -0.126297  ...  0.018180  0.002486 -0.003433   \n",
      "16151  0.237629 -0.153675  0.824447  ... -0.000302 -0.001857  0.000926   \n",
      "\n",
      "             93        94        95        96        97        98        99  \n",
      "0     -0.004322  0.006665  0.000154 -0.000415 -0.000354 -0.000091 -0.000327  \n",
      "1     -0.000090  0.001927 -0.001082  0.000734  0.000013 -0.000024 -0.000023  \n",
      "2      0.003680  0.000885 -0.010856  0.004714  0.003993 -0.009701 -0.002252  \n",
      "3     -0.001499 -0.001336  0.004994 -0.002799  0.001485 -0.002247 -0.001430  \n",
      "4     -0.004051  0.004494  0.005512 -0.001940  0.001753  0.002529  0.001898  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "16147  0.003184 -0.003424 -0.004577  0.001228  0.000019  0.002936 -0.000603  \n",
      "16148  0.004795 -0.002888 -0.006555  0.003109 -0.002294  0.002717  0.000485  \n",
      "16149 -0.003600  0.004718  0.004555 -0.000853  0.000057 -0.000552  0.000665  \n",
      "16150  0.007989 -0.004918 -0.013880 -0.013296 -0.016223 -0.023784  0.003310  \n",
      "16151 -0.000688 -0.000163  0.002414  0.000768 -0.001201  0.001295  0.000216  \n",
      "\n",
      "[16152 rows x 100 columns]>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "principalComponents = pca.fit_transform(X_ros)\n",
    "X_ros = principalComponents\n",
    "principalDf = pd.DataFrame(principalComponents)\n",
    "print(principalDf.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10821, 100)\n",
      "[[ 6.52231902e-01 -4.87181021e-01  3.11628542e-01 ... -4.63591669e-04\n",
      "   8.25865177e-05  2.20320116e-04]\n",
      " [-5.49913395e-01  1.91068377e-01 -1.14743001e-01 ...  8.39310152e-04\n",
      "   4.84601367e-04 -7.65840319e-04]\n",
      " [ 6.91205407e-03  1.56107809e-01 -4.63325653e-01 ... -7.08418975e-04\n",
      "  -2.51128577e-03 -9.18283714e-04]\n",
      " ...\n",
      " [ 1.05684839e+00 -4.35524569e-01 -6.00252531e-01 ...  9.93099847e-04\n",
      "  -2.94882939e-03 -7.26746234e-04]\n",
      " [ 1.04796984e+00 -3.91273422e-01 -9.13012846e-02 ... -1.83127781e-04\n",
      "  -2.54861330e-03  4.90637943e-04]\n",
      " [-6.70006515e-01  2.86056898e-03 -5.57240018e-01 ... -3.30549528e-04\n",
      "   1.26747651e-03 -3.45025035e-05]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting training and testing data\n",
    "(X_train, X_Test, Y_train, Y_Test) = train_test_split(X_ros, Y_ros, test_size = 0.33)\n",
    "print(X_train.shape)\n",
    "print(X_train[1:100])\n",
    "\n",
    "#Defining our DL model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(tf.keras.layers.Reshape((100,),input_shape = (100,)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#hidden layers\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(8, activation = \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(8, activation = \"relu\"))\n",
    "\n",
    "#output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "#compiling the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10821 samples, validate on 5331 samples\n",
      "Epoch 1/500\n",
      "10821/10821 [==============================] - 1s 79us/sample - loss: 0.6955 - accuracy: 0.5353 - val_loss: 0.6906 - val_accuracy: 0.5164\n",
      "Epoch 2/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.6670 - accuracy: 0.6100 - val_loss: 0.6739 - val_accuracy: 0.6143\n",
      "Epoch 3/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.6334 - accuracy: 0.6583 - val_loss: 0.6436 - val_accuracy: 0.6376\n",
      "Epoch 4/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.5937 - accuracy: 0.6932 - val_loss: 0.6079 - val_accuracy: 0.6732\n",
      "Epoch 5/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.5607 - accuracy: 0.7219 - val_loss: 0.5856 - val_accuracy: 0.6976\n",
      "Epoch 6/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.5358 - accuracy: 0.7385 - val_loss: 0.5677 - val_accuracy: 0.7154\n",
      "Epoch 7/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.5171 - accuracy: 0.7505 - val_loss: 0.5532 - val_accuracy: 0.7259\n",
      "Epoch 8/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4984 - accuracy: 0.7629 - val_loss: 0.5354 - val_accuracy: 0.7361\n",
      "Epoch 9/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4842 - accuracy: 0.7727 - val_loss: 0.5174 - val_accuracy: 0.7496\n",
      "Epoch 10/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4687 - accuracy: 0.7804 - val_loss: 0.4989 - val_accuracy: 0.7651\n",
      "Epoch 11/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4542 - accuracy: 0.7911 - val_loss: 0.4818 - val_accuracy: 0.7787\n",
      "Epoch 12/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4388 - accuracy: 0.8006 - val_loss: 0.4669 - val_accuracy: 0.7856\n",
      "Epoch 13/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4236 - accuracy: 0.8118 - val_loss: 0.4566 - val_accuracy: 0.7974\n",
      "Epoch 14/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4149 - accuracy: 0.8188 - val_loss: 0.4513 - val_accuracy: 0.8006\n",
      "Epoch 15/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.4044 - accuracy: 0.8280 - val_loss: 0.4388 - val_accuracy: 0.8047\n",
      "Epoch 16/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3974 - accuracy: 0.8273 - val_loss: 0.4291 - val_accuracy: 0.8089\n",
      "Epoch 17/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3872 - accuracy: 0.8372 - val_loss: 0.4220 - val_accuracy: 0.8177\n",
      "Epoch 18/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3776 - accuracy: 0.8420 - val_loss: 0.4132 - val_accuracy: 0.8278\n",
      "Epoch 19/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3675 - accuracy: 0.8476 - val_loss: 0.4076 - val_accuracy: 0.8280\n",
      "Epoch 20/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3664 - accuracy: 0.8477 - val_loss: 0.4048 - val_accuracy: 0.8302\n",
      "Epoch 21/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3574 - accuracy: 0.8557 - val_loss: 0.4005 - val_accuracy: 0.8368\n",
      "Epoch 22/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3482 - accuracy: 0.8598 - val_loss: 0.3958 - val_accuracy: 0.8351\n",
      "Epoch 23/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3469 - accuracy: 0.8583 - val_loss: 0.3931 - val_accuracy: 0.8413\n",
      "Epoch 24/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3489 - accuracy: 0.8581 - val_loss: 0.3884 - val_accuracy: 0.8392\n",
      "Epoch 25/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3346 - accuracy: 0.8673 - val_loss: 0.3877 - val_accuracy: 0.8441\n",
      "Epoch 26/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3343 - accuracy: 0.8691 - val_loss: 0.3825 - val_accuracy: 0.8471\n",
      "Epoch 27/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3299 - accuracy: 0.8716 - val_loss: 0.3770 - val_accuracy: 0.8445\n",
      "Epoch 28/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3216 - accuracy: 0.8727 - val_loss: 0.3785 - val_accuracy: 0.8473\n",
      "Epoch 29/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3240 - accuracy: 0.8697 - val_loss: 0.3755 - val_accuracy: 0.8554\n",
      "Epoch 30/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3230 - accuracy: 0.8756 - val_loss: 0.3726 - val_accuracy: 0.8563\n",
      "Epoch 31/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3167 - accuracy: 0.8756 - val_loss: 0.3707 - val_accuracy: 0.8574\n",
      "Epoch 32/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3163 - accuracy: 0.8776 - val_loss: 0.3681 - val_accuracy: 0.8552\n",
      "Epoch 33/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3092 - accuracy: 0.8815 - val_loss: 0.3634 - val_accuracy: 0.8597\n",
      "Epoch 34/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3124 - accuracy: 0.8778 - val_loss: 0.3639 - val_accuracy: 0.8614\n",
      "Epoch 35/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3109 - accuracy: 0.8805 - val_loss: 0.3627 - val_accuracy: 0.8619\n",
      "Epoch 36/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3068 - accuracy: 0.8785 - val_loss: 0.3669 - val_accuracy: 0.8527\n",
      "Epoch 37/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.3018 - accuracy: 0.8832 - val_loss: 0.3604 - val_accuracy: 0.8636\n",
      "Epoch 38/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2986 - accuracy: 0.8832 - val_loss: 0.3589 - val_accuracy: 0.8625\n",
      "Epoch 39/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2957 - accuracy: 0.8851 - val_loss: 0.3633 - val_accuracy: 0.8636\n",
      "Epoch 40/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2983 - accuracy: 0.8808 - val_loss: 0.3652 - val_accuracy: 0.8597\n",
      "Epoch 41/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2946 - accuracy: 0.8851 - val_loss: 0.3575 - val_accuracy: 0.8670\n",
      "Epoch 42/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2979 - accuracy: 0.8855 - val_loss: 0.3595 - val_accuracy: 0.8648\n",
      "Epoch 43/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2948 - accuracy: 0.8868 - val_loss: 0.3569 - val_accuracy: 0.8633\n",
      "Epoch 44/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2901 - accuracy: 0.8867 - val_loss: 0.3579 - val_accuracy: 0.8633\n",
      "Epoch 45/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2895 - accuracy: 0.8871 - val_loss: 0.3543 - val_accuracy: 0.8638\n",
      "Epoch 46/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2888 - accuracy: 0.8900 - val_loss: 0.3532 - val_accuracy: 0.8698\n",
      "Epoch 47/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2864 - accuracy: 0.8873 - val_loss: 0.3511 - val_accuracy: 0.8685\n",
      "Epoch 48/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2908 - accuracy: 0.8866 - val_loss: 0.3557 - val_accuracy: 0.8704\n",
      "Epoch 49/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2834 - accuracy: 0.8914 - val_loss: 0.3491 - val_accuracy: 0.8668\n",
      "Epoch 50/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2835 - accuracy: 0.8922 - val_loss: 0.3516 - val_accuracy: 0.8685\n",
      "Epoch 51/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2842 - accuracy: 0.8922 - val_loss: 0.3461 - val_accuracy: 0.8736\n",
      "Epoch 52/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2808 - accuracy: 0.8910 - val_loss: 0.3447 - val_accuracy: 0.8664\n",
      "Epoch 53/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2785 - accuracy: 0.8921 - val_loss: 0.3447 - val_accuracy: 0.8694\n",
      "Epoch 54/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2786 - accuracy: 0.8923 - val_loss: 0.3423 - val_accuracy: 0.8726\n",
      "Epoch 55/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2746 - accuracy: 0.8924 - val_loss: 0.3418 - val_accuracy: 0.8783\n",
      "Epoch 56/500\n",
      "10821/10821 [==============================] - 0s 13us/sample - loss: 0.2743 - accuracy: 0.8928 - val_loss: 0.3477 - val_accuracy: 0.8743\n",
      "Epoch 57/500\n",
      "10821/10821 [==============================] - 0s 13us/sample - loss: 0.2702 - accuracy: 0.8971 - val_loss: 0.3375 - val_accuracy: 0.8771\n",
      "Epoch 58/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2728 - accuracy: 0.8936 - val_loss: 0.3434 - val_accuracy: 0.8698\n",
      "Epoch 59/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2668 - accuracy: 0.8971 - val_loss: 0.3384 - val_accuracy: 0.8790\n",
      "Epoch 60/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2646 - accuracy: 0.8984 - val_loss: 0.3455 - val_accuracy: 0.8798\n",
      "Epoch 61/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2666 - accuracy: 0.8958 - val_loss: 0.3397 - val_accuracy: 0.8704\n",
      "Epoch 62/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2674 - accuracy: 0.8952 - val_loss: 0.3445 - val_accuracy: 0.8798\n",
      "Epoch 63/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2614 - accuracy: 0.9003 - val_loss: 0.3370 - val_accuracy: 0.8818\n",
      "Epoch 64/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2648 - accuracy: 0.8992 - val_loss: 0.3357 - val_accuracy: 0.8801\n",
      "Epoch 65/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2613 - accuracy: 0.9017 - val_loss: 0.3386 - val_accuracy: 0.8818\n",
      "Epoch 66/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2630 - accuracy: 0.8948 - val_loss: 0.3334 - val_accuracy: 0.8807\n",
      "Epoch 67/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2607 - accuracy: 0.8994 - val_loss: 0.3370 - val_accuracy: 0.8863\n",
      "Epoch 68/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2548 - accuracy: 0.9045 - val_loss: 0.3319 - val_accuracy: 0.8807\n",
      "Epoch 69/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2575 - accuracy: 0.9026 - val_loss: 0.3355 - val_accuracy: 0.8873\n",
      "Epoch 70/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2577 - accuracy: 0.9030 - val_loss: 0.3299 - val_accuracy: 0.8835\n",
      "Epoch 71/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2569 - accuracy: 0.9024 - val_loss: 0.3319 - val_accuracy: 0.8844\n",
      "Epoch 72/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2531 - accuracy: 0.9027 - val_loss: 0.3334 - val_accuracy: 0.8813\n",
      "Epoch 73/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2551 - accuracy: 0.8999 - val_loss: 0.3351 - val_accuracy: 0.8833\n",
      "Epoch 74/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2512 - accuracy: 0.9042 - val_loss: 0.3339 - val_accuracy: 0.8816\n",
      "Epoch 75/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2491 - accuracy: 0.9056 - val_loss: 0.3289 - val_accuracy: 0.8798\n",
      "Epoch 76/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2463 - accuracy: 0.9076 - val_loss: 0.3282 - val_accuracy: 0.8779\n",
      "Epoch 77/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2511 - accuracy: 0.9048 - val_loss: 0.3304 - val_accuracy: 0.8786\n",
      "Epoch 78/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2458 - accuracy: 0.9057 - val_loss: 0.3343 - val_accuracy: 0.8833\n",
      "Epoch 79/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2492 - accuracy: 0.9047 - val_loss: 0.3208 - val_accuracy: 0.8843\n",
      "Epoch 80/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2419 - accuracy: 0.9101 - val_loss: 0.3237 - val_accuracy: 0.8826\n",
      "Epoch 81/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2414 - accuracy: 0.9095 - val_loss: 0.3209 - val_accuracy: 0.8788\n",
      "Epoch 82/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2458 - accuracy: 0.9081 - val_loss: 0.3322 - val_accuracy: 0.8856\n",
      "Epoch 83/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2394 - accuracy: 0.9080 - val_loss: 0.3180 - val_accuracy: 0.8861\n",
      "Epoch 84/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2396 - accuracy: 0.9096 - val_loss: 0.3283 - val_accuracy: 0.8912\n",
      "Epoch 85/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2430 - accuracy: 0.9074 - val_loss: 0.3228 - val_accuracy: 0.8901\n",
      "Epoch 86/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2379 - accuracy: 0.9120 - val_loss: 0.3250 - val_accuracy: 0.8873\n",
      "Epoch 87/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2416 - accuracy: 0.9080 - val_loss: 0.3255 - val_accuracy: 0.8920\n",
      "Epoch 88/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2383 - accuracy: 0.9106 - val_loss: 0.3241 - val_accuracy: 0.8867\n",
      "Epoch 89/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2386 - accuracy: 0.9125 - val_loss: 0.3195 - val_accuracy: 0.8903\n",
      "Epoch 90/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2362 - accuracy: 0.9110 - val_loss: 0.3182 - val_accuracy: 0.8905\n",
      "Epoch 91/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2328 - accuracy: 0.9144 - val_loss: 0.3183 - val_accuracy: 0.8895\n",
      "Epoch 92/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2290 - accuracy: 0.9168 - val_loss: 0.3163 - val_accuracy: 0.8921\n",
      "Epoch 93/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2351 - accuracy: 0.9117 - val_loss: 0.3125 - val_accuracy: 0.8931\n",
      "Epoch 94/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2315 - accuracy: 0.9143 - val_loss: 0.3172 - val_accuracy: 0.8914\n",
      "Epoch 95/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2370 - accuracy: 0.9104 - val_loss: 0.3098 - val_accuracy: 0.8950\n",
      "Epoch 96/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2289 - accuracy: 0.9140 - val_loss: 0.3192 - val_accuracy: 0.8891\n",
      "Epoch 97/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2292 - accuracy: 0.9132 - val_loss: 0.3195 - val_accuracy: 0.8920\n",
      "Epoch 98/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2234 - accuracy: 0.9201 - val_loss: 0.3241 - val_accuracy: 0.8927\n",
      "Epoch 99/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2316 - accuracy: 0.9140 - val_loss: 0.3108 - val_accuracy: 0.8935\n",
      "Epoch 100/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2309 - accuracy: 0.9166 - val_loss: 0.3181 - val_accuracy: 0.8920\n",
      "Epoch 101/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2283 - accuracy: 0.9141 - val_loss: 0.3169 - val_accuracy: 0.8890\n",
      "Epoch 102/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2272 - accuracy: 0.9141 - val_loss: 0.3125 - val_accuracy: 0.8931\n",
      "Epoch 103/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2265 - accuracy: 0.9194 - val_loss: 0.3199 - val_accuracy: 0.8914\n",
      "Epoch 104/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2238 - accuracy: 0.9186 - val_loss: 0.3130 - val_accuracy: 0.8948\n",
      "Epoch 105/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2290 - accuracy: 0.9112 - val_loss: 0.3170 - val_accuracy: 0.8890\n",
      "Epoch 106/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2256 - accuracy: 0.9144 - val_loss: 0.3179 - val_accuracy: 0.8906\n",
      "Epoch 107/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2191 - accuracy: 0.9198 - val_loss: 0.3101 - val_accuracy: 0.8948\n",
      "Epoch 108/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2204 - accuracy: 0.9184 - val_loss: 0.3120 - val_accuracy: 0.8935\n",
      "Epoch 109/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2266 - accuracy: 0.9146 - val_loss: 0.3054 - val_accuracy: 0.8963\n",
      "Epoch 110/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2238 - accuracy: 0.9174 - val_loss: 0.3261 - val_accuracy: 0.8901\n",
      "Epoch 111/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2239 - accuracy: 0.9148 - val_loss: 0.3254 - val_accuracy: 0.8905\n",
      "Epoch 112/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2241 - accuracy: 0.9154 - val_loss: 0.3195 - val_accuracy: 0.8921\n",
      "Epoch 113/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2181 - accuracy: 0.9193 - val_loss: 0.3097 - val_accuracy: 0.8925\n",
      "Epoch 114/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2231 - accuracy: 0.9174 - val_loss: 0.3103 - val_accuracy: 0.8936\n",
      "Epoch 115/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2197 - accuracy: 0.9193 - val_loss: 0.3229 - val_accuracy: 0.8888\n",
      "Epoch 116/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2255 - accuracy: 0.9132 - val_loss: 0.3089 - val_accuracy: 0.8925\n",
      "Epoch 117/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2183 - accuracy: 0.9187 - val_loss: 0.3060 - val_accuracy: 0.8936\n",
      "Epoch 118/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2204 - accuracy: 0.9166 - val_loss: 0.3086 - val_accuracy: 0.8927\n",
      "Epoch 119/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2190 - accuracy: 0.9187 - val_loss: 0.3106 - val_accuracy: 0.8966\n",
      "Epoch 120/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2155 - accuracy: 0.9211 - val_loss: 0.3149 - val_accuracy: 0.8921\n",
      "Epoch 121/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2187 - accuracy: 0.9179 - val_loss: 0.3107 - val_accuracy: 0.8968\n",
      "Epoch 122/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2139 - accuracy: 0.9222 - val_loss: 0.3057 - val_accuracy: 0.8953\n",
      "Epoch 123/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2110 - accuracy: 0.9240 - val_loss: 0.3095 - val_accuracy: 0.8968\n",
      "Epoch 124/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2172 - accuracy: 0.9220 - val_loss: 0.2991 - val_accuracy: 0.8978\n",
      "Epoch 125/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2114 - accuracy: 0.9231 - val_loss: 0.3079 - val_accuracy: 0.8976\n",
      "Epoch 126/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2148 - accuracy: 0.9198 - val_loss: 0.3136 - val_accuracy: 0.8966\n",
      "Epoch 127/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2215 - accuracy: 0.9182 - val_loss: 0.2998 - val_accuracy: 0.9010\n",
      "Epoch 128/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2146 - accuracy: 0.9202 - val_loss: 0.3027 - val_accuracy: 0.8981\n",
      "Epoch 129/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2138 - accuracy: 0.9212 - val_loss: 0.3062 - val_accuracy: 0.8974\n",
      "Epoch 130/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2168 - accuracy: 0.9244 - val_loss: 0.3018 - val_accuracy: 0.9000\n",
      "Epoch 131/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2146 - accuracy: 0.9228 - val_loss: 0.3060 - val_accuracy: 0.9023\n",
      "Epoch 132/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2094 - accuracy: 0.9239 - val_loss: 0.3025 - val_accuracy: 0.9010\n",
      "Epoch 133/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2138 - accuracy: 0.9214 - val_loss: 0.3025 - val_accuracy: 0.9026\n",
      "Epoch 134/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2151 - accuracy: 0.9211 - val_loss: 0.3128 - val_accuracy: 0.9000\n",
      "Epoch 135/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2176 - accuracy: 0.9208 - val_loss: 0.3092 - val_accuracy: 0.9030\n",
      "Epoch 136/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2152 - accuracy: 0.9202 - val_loss: 0.3056 - val_accuracy: 0.8995\n",
      "Epoch 137/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2147 - accuracy: 0.9213 - val_loss: 0.3087 - val_accuracy: 0.9011\n",
      "Epoch 138/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2087 - accuracy: 0.9243 - val_loss: 0.3046 - val_accuracy: 0.8987\n",
      "Epoch 139/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2068 - accuracy: 0.9234 - val_loss: 0.3076 - val_accuracy: 0.9010\n",
      "Epoch 140/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2070 - accuracy: 0.9230 - val_loss: 0.3045 - val_accuracy: 0.9019\n",
      "Epoch 141/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2063 - accuracy: 0.9257 - val_loss: 0.2996 - val_accuracy: 0.9017\n",
      "Epoch 142/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2094 - accuracy: 0.9203 - val_loss: 0.2983 - val_accuracy: 0.9034\n",
      "Epoch 143/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2151 - accuracy: 0.9201 - val_loss: 0.3122 - val_accuracy: 0.8980\n",
      "Epoch 144/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2139 - accuracy: 0.9202 - val_loss: 0.3026 - val_accuracy: 0.9021\n",
      "Epoch 145/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2049 - accuracy: 0.9268 - val_loss: 0.3074 - val_accuracy: 0.9030\n",
      "Epoch 146/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2096 - accuracy: 0.9243 - val_loss: 0.2988 - val_accuracy: 0.9010\n",
      "Epoch 147/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2078 - accuracy: 0.9239 - val_loss: 0.3003 - val_accuracy: 0.9021\n",
      "Epoch 148/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2082 - accuracy: 0.9238 - val_loss: 0.3053 - val_accuracy: 0.8991\n",
      "Epoch 149/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2093 - accuracy: 0.9232 - val_loss: 0.2993 - val_accuracy: 0.9023\n",
      "Epoch 150/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2015 - accuracy: 0.9265 - val_loss: 0.3041 - val_accuracy: 0.8993\n",
      "Epoch 151/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2036 - accuracy: 0.9253 - val_loss: 0.3013 - val_accuracy: 0.9010\n",
      "Epoch 152/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2051 - accuracy: 0.9251 - val_loss: 0.3032 - val_accuracy: 0.9006\n",
      "Epoch 153/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2010 - accuracy: 0.9263 - val_loss: 0.3087 - val_accuracy: 0.8983\n",
      "Epoch 154/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2069 - accuracy: 0.9241 - val_loss: 0.3012 - val_accuracy: 0.9025\n",
      "Epoch 155/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2066 - accuracy: 0.9223 - val_loss: 0.3050 - val_accuracy: 0.9002\n",
      "Epoch 156/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2002 - accuracy: 0.9268 - val_loss: 0.3030 - val_accuracy: 0.9015\n",
      "Epoch 157/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2017 - accuracy: 0.9243 - val_loss: 0.3066 - val_accuracy: 0.8991\n",
      "Epoch 158/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2031 - accuracy: 0.9275 - val_loss: 0.3071 - val_accuracy: 0.9006\n",
      "Epoch 159/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2117 - accuracy: 0.9206 - val_loss: 0.3162 - val_accuracy: 0.8989\n",
      "Epoch 160/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2039 - accuracy: 0.9259 - val_loss: 0.3071 - val_accuracy: 0.9010\n",
      "Epoch 161/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2017 - accuracy: 0.9263 - val_loss: 0.3084 - val_accuracy: 0.9017\n",
      "Epoch 162/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2006 - accuracy: 0.9241 - val_loss: 0.3171 - val_accuracy: 0.8989\n",
      "Epoch 163/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1999 - accuracy: 0.9274 - val_loss: 0.3126 - val_accuracy: 0.9004\n",
      "Epoch 164/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2040 - accuracy: 0.9249 - val_loss: 0.3171 - val_accuracy: 0.8998\n",
      "Epoch 165/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1969 - accuracy: 0.9298 - val_loss: 0.3065 - val_accuracy: 0.9034\n",
      "Epoch 166/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2013 - accuracy: 0.9242 - val_loss: 0.3071 - val_accuracy: 0.9032\n",
      "Epoch 167/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.2012 - accuracy: 0.9260 - val_loss: 0.3144 - val_accuracy: 0.8998\n",
      "Epoch 168/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1987 - accuracy: 0.9270 - val_loss: 0.3036 - val_accuracy: 0.9051\n",
      "Epoch 169/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.2077 - accuracy: 0.9223 - val_loss: 0.3264 - val_accuracy: 0.8963\n",
      "Epoch 170/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1999 - accuracy: 0.9290 - val_loss: 0.2981 - val_accuracy: 0.9045\n",
      "Epoch 171/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1982 - accuracy: 0.9283 - val_loss: 0.3075 - val_accuracy: 0.9004\n",
      "Epoch 172/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1962 - accuracy: 0.9295 - val_loss: 0.2985 - val_accuracy: 0.9038\n",
      "Epoch 173/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.2002 - accuracy: 0.9264 - val_loss: 0.2994 - val_accuracy: 0.9051\n",
      "Epoch 174/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1955 - accuracy: 0.9258 - val_loss: 0.3099 - val_accuracy: 0.8996\n",
      "Epoch 175/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1955 - accuracy: 0.9293 - val_loss: 0.3007 - val_accuracy: 0.9062\n",
      "Epoch 176/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1985 - accuracy: 0.9266 - val_loss: 0.3013 - val_accuracy: 0.9055\n",
      "Epoch 177/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1910 - accuracy: 0.9298 - val_loss: 0.3052 - val_accuracy: 0.9045\n",
      "Epoch 178/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1995 - accuracy: 0.9266 - val_loss: 0.3060 - val_accuracy: 0.9030\n",
      "Epoch 179/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1976 - accuracy: 0.9276 - val_loss: 0.3021 - val_accuracy: 0.9049\n",
      "Epoch 180/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1967 - accuracy: 0.9277 - val_loss: 0.3030 - val_accuracy: 0.9049\n",
      "Epoch 181/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1980 - accuracy: 0.9302 - val_loss: 0.3018 - val_accuracy: 0.9053\n",
      "Epoch 182/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1945 - accuracy: 0.9277 - val_loss: 0.2979 - val_accuracy: 0.9021\n",
      "Epoch 183/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1969 - accuracy: 0.9282 - val_loss: 0.3014 - val_accuracy: 0.9038\n",
      "Epoch 184/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1908 - accuracy: 0.9292 - val_loss: 0.3146 - val_accuracy: 0.9017\n",
      "Epoch 185/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1963 - accuracy: 0.9290 - val_loss: 0.3105 - val_accuracy: 0.9064\n",
      "Epoch 186/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1949 - accuracy: 0.9286 - val_loss: 0.3189 - val_accuracy: 0.9019\n",
      "Epoch 187/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1910 - accuracy: 0.9314 - val_loss: 0.3088 - val_accuracy: 0.9019\n",
      "Epoch 188/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1928 - accuracy: 0.9308 - val_loss: 0.3062 - val_accuracy: 0.9053\n",
      "Epoch 189/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1906 - accuracy: 0.9307 - val_loss: 0.3079 - val_accuracy: 0.9030\n",
      "Epoch 190/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1941 - accuracy: 0.9287 - val_loss: 0.3150 - val_accuracy: 0.9025\n",
      "Epoch 191/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1905 - accuracy: 0.9293 - val_loss: 0.3116 - val_accuracy: 0.9026\n",
      "Epoch 192/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1888 - accuracy: 0.9312 - val_loss: 0.3049 - val_accuracy: 0.9070\n",
      "Epoch 193/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1888 - accuracy: 0.9313 - val_loss: 0.3102 - val_accuracy: 0.9056\n",
      "Epoch 194/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1866 - accuracy: 0.9328 - val_loss: 0.3094 - val_accuracy: 0.9070\n",
      "Epoch 195/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1930 - accuracy: 0.9313 - val_loss: 0.3162 - val_accuracy: 0.9013\n",
      "Epoch 196/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1991 - accuracy: 0.9260 - val_loss: 0.3116 - val_accuracy: 0.9055\n",
      "Epoch 197/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1938 - accuracy: 0.9264 - val_loss: 0.3129 - val_accuracy: 0.9038\n",
      "Epoch 198/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1920 - accuracy: 0.9306 - val_loss: 0.3062 - val_accuracy: 0.9064\n",
      "Epoch 199/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1849 - accuracy: 0.9345 - val_loss: 0.3096 - val_accuracy: 0.9060\n",
      "Epoch 200/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1928 - accuracy: 0.9292 - val_loss: 0.3027 - val_accuracy: 0.9075\n",
      "Epoch 201/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1949 - accuracy: 0.9286 - val_loss: 0.3114 - val_accuracy: 0.9026\n",
      "Epoch 202/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1909 - accuracy: 0.9295 - val_loss: 0.3131 - val_accuracy: 0.9043\n",
      "Epoch 203/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1891 - accuracy: 0.9320 - val_loss: 0.3015 - val_accuracy: 0.9086\n",
      "Epoch 204/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1870 - accuracy: 0.9316 - val_loss: 0.3251 - val_accuracy: 0.8980\n",
      "Epoch 205/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1918 - accuracy: 0.9294 - val_loss: 0.3039 - val_accuracy: 0.9079\n",
      "Epoch 206/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1879 - accuracy: 0.9335 - val_loss: 0.3189 - val_accuracy: 0.9017\n",
      "Epoch 207/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1970 - accuracy: 0.9251 - val_loss: 0.3213 - val_accuracy: 0.8993\n",
      "Epoch 208/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1940 - accuracy: 0.9294 - val_loss: 0.3086 - val_accuracy: 0.9049\n",
      "Epoch 209/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1879 - accuracy: 0.9311 - val_loss: 0.2997 - val_accuracy: 0.9113\n",
      "Epoch 210/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1901 - accuracy: 0.9281 - val_loss: 0.3109 - val_accuracy: 0.9049\n",
      "Epoch 211/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1805 - accuracy: 0.9335 - val_loss: 0.3159 - val_accuracy: 0.9043\n",
      "Epoch 212/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1879 - accuracy: 0.9319 - val_loss: 0.3217 - val_accuracy: 0.9032\n",
      "Epoch 213/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1872 - accuracy: 0.9327 - val_loss: 0.3166 - val_accuracy: 0.9060\n",
      "Epoch 214/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1924 - accuracy: 0.9290 - val_loss: 0.3252 - val_accuracy: 0.9028\n",
      "Epoch 215/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1963 - accuracy: 0.9261 - val_loss: 0.3157 - val_accuracy: 0.9011\n",
      "Epoch 216/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1870 - accuracy: 0.9311 - val_loss: 0.3101 - val_accuracy: 0.9058\n",
      "Epoch 217/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1901 - accuracy: 0.9312 - val_loss: 0.3146 - val_accuracy: 0.9056\n",
      "Epoch 218/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1827 - accuracy: 0.9331 - val_loss: 0.3108 - val_accuracy: 0.9030\n",
      "Epoch 219/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1856 - accuracy: 0.9308 - val_loss: 0.3107 - val_accuracy: 0.9062\n",
      "Epoch 220/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1835 - accuracy: 0.9321 - val_loss: 0.3209 - val_accuracy: 0.9011\n",
      "Epoch 221/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1785 - accuracy: 0.9369 - val_loss: 0.3219 - val_accuracy: 0.8993\n",
      "Epoch 222/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1878 - accuracy: 0.9309 - val_loss: 0.3060 - val_accuracy: 0.9038\n",
      "Epoch 223/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1832 - accuracy: 0.9327 - val_loss: 0.3136 - val_accuracy: 0.8996\n",
      "Epoch 224/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1779 - accuracy: 0.9356 - val_loss: 0.3159 - val_accuracy: 0.9019\n",
      "Epoch 225/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1812 - accuracy: 0.9327 - val_loss: 0.3052 - val_accuracy: 0.9068\n",
      "Epoch 226/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1786 - accuracy: 0.9335 - val_loss: 0.3082 - val_accuracy: 0.9051\n",
      "Epoch 227/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1814 - accuracy: 0.9364 - val_loss: 0.3254 - val_accuracy: 0.9019\n",
      "Epoch 228/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1818 - accuracy: 0.9334 - val_loss: 0.3121 - val_accuracy: 0.9066\n",
      "Epoch 229/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1862 - accuracy: 0.9310 - val_loss: 0.3327 - val_accuracy: 0.9025\n",
      "Epoch 230/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1893 - accuracy: 0.9298 - val_loss: 0.3259 - val_accuracy: 0.9026\n",
      "Epoch 231/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1944 - accuracy: 0.9295 - val_loss: 0.3215 - val_accuracy: 0.9058\n",
      "Epoch 232/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1869 - accuracy: 0.9313 - val_loss: 0.3228 - val_accuracy: 0.9021\n",
      "Epoch 233/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1842 - accuracy: 0.9330 - val_loss: 0.3232 - val_accuracy: 0.9004\n",
      "Epoch 234/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1935 - accuracy: 0.9306 - val_loss: 0.3316 - val_accuracy: 0.8978\n",
      "Epoch 235/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1837 - accuracy: 0.9332 - val_loss: 0.3197 - val_accuracy: 0.9038\n",
      "Epoch 236/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1856 - accuracy: 0.9314 - val_loss: 0.3127 - val_accuracy: 0.9041\n",
      "Epoch 237/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1889 - accuracy: 0.9315 - val_loss: 0.3146 - val_accuracy: 0.9041\n",
      "Epoch 238/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1878 - accuracy: 0.9318 - val_loss: 0.3154 - val_accuracy: 0.9028\n",
      "Epoch 239/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1855 - accuracy: 0.9312 - val_loss: 0.3131 - val_accuracy: 0.9034\n",
      "Epoch 240/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1800 - accuracy: 0.9335 - val_loss: 0.3307 - val_accuracy: 0.9011\n",
      "Epoch 241/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1838 - accuracy: 0.9338 - val_loss: 0.3163 - val_accuracy: 0.9053\n",
      "Epoch 242/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1833 - accuracy: 0.9326 - val_loss: 0.3078 - val_accuracy: 0.9064\n",
      "Epoch 243/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1844 - accuracy: 0.9297 - val_loss: 0.3127 - val_accuracy: 0.9055\n",
      "Epoch 244/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1865 - accuracy: 0.9311 - val_loss: 0.3071 - val_accuracy: 0.9051\n",
      "Epoch 245/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1853 - accuracy: 0.9327 - val_loss: 0.3103 - val_accuracy: 0.9036\n",
      "Epoch 246/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1805 - accuracy: 0.9350 - val_loss: 0.3048 - val_accuracy: 0.9073\n",
      "Epoch 247/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1822 - accuracy: 0.9345 - val_loss: 0.3066 - val_accuracy: 0.9075\n",
      "Epoch 248/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1814 - accuracy: 0.9349 - val_loss: 0.3019 - val_accuracy: 0.9092\n",
      "Epoch 249/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1804 - accuracy: 0.9367 - val_loss: 0.3172 - val_accuracy: 0.9036\n",
      "Epoch 250/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1751 - accuracy: 0.9364 - val_loss: 0.3170 - val_accuracy: 0.9055\n",
      "Epoch 251/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1784 - accuracy: 0.9356 - val_loss: 0.3097 - val_accuracy: 0.9062\n",
      "Epoch 252/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1829 - accuracy: 0.9348 - val_loss: 0.3032 - val_accuracy: 0.9105\n",
      "Epoch 253/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1798 - accuracy: 0.9352 - val_loss: 0.3060 - val_accuracy: 0.9077\n",
      "Epoch 254/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1854 - accuracy: 0.9321 - val_loss: 0.3068 - val_accuracy: 0.9083\n",
      "Epoch 255/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1822 - accuracy: 0.9309 - val_loss: 0.3035 - val_accuracy: 0.9116\n",
      "Epoch 256/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1798 - accuracy: 0.9391 - val_loss: 0.3127 - val_accuracy: 0.9075\n",
      "Epoch 257/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1868 - accuracy: 0.9295 - val_loss: 0.3119 - val_accuracy: 0.9071\n",
      "Epoch 258/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1784 - accuracy: 0.9359 - val_loss: 0.3029 - val_accuracy: 0.9103\n",
      "Epoch 259/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1826 - accuracy: 0.9336 - val_loss: 0.3083 - val_accuracy: 0.9092\n",
      "Epoch 260/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1775 - accuracy: 0.9350 - val_loss: 0.3020 - val_accuracy: 0.9105\n",
      "Epoch 261/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1832 - accuracy: 0.9332 - val_loss: 0.3064 - val_accuracy: 0.9086\n",
      "Epoch 262/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1831 - accuracy: 0.9329 - val_loss: 0.3035 - val_accuracy: 0.9107\n",
      "Epoch 263/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1801 - accuracy: 0.9361 - val_loss: 0.3095 - val_accuracy: 0.9086\n",
      "Epoch 264/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1806 - accuracy: 0.9363 - val_loss: 0.3198 - val_accuracy: 0.9034\n",
      "Epoch 265/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1798 - accuracy: 0.9318 - val_loss: 0.3149 - val_accuracy: 0.9073\n",
      "Epoch 266/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1822 - accuracy: 0.9321 - val_loss: 0.3096 - val_accuracy: 0.9096\n",
      "Epoch 267/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1791 - accuracy: 0.9361 - val_loss: 0.3099 - val_accuracy: 0.9075\n",
      "Epoch 268/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1799 - accuracy: 0.9348 - val_loss: 0.3040 - val_accuracy: 0.9139\n",
      "Epoch 269/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1777 - accuracy: 0.9373 - val_loss: 0.3079 - val_accuracy: 0.9079\n",
      "Epoch 270/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1782 - accuracy: 0.9365 - val_loss: 0.3113 - val_accuracy: 0.9088\n",
      "Epoch 271/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1803 - accuracy: 0.9350 - val_loss: 0.3136 - val_accuracy: 0.9083\n",
      "Epoch 272/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1746 - accuracy: 0.9392 - val_loss: 0.3117 - val_accuracy: 0.9056\n",
      "Epoch 273/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1738 - accuracy: 0.9383 - val_loss: 0.3166 - val_accuracy: 0.9049\n",
      "Epoch 274/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1830 - accuracy: 0.9322 - val_loss: 0.3357 - val_accuracy: 0.9055\n",
      "Epoch 275/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1781 - accuracy: 0.9356 - val_loss: 0.3109 - val_accuracy: 0.9066\n",
      "Epoch 276/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1717 - accuracy: 0.9382 - val_loss: 0.3122 - val_accuracy: 0.9070\n",
      "Epoch 277/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1817 - accuracy: 0.9351 - val_loss: 0.3205 - val_accuracy: 0.9071\n",
      "Epoch 278/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1840 - accuracy: 0.9326 - val_loss: 0.3078 - val_accuracy: 0.9094\n",
      "Epoch 279/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1763 - accuracy: 0.9357 - val_loss: 0.3134 - val_accuracy: 0.9086\n",
      "Epoch 280/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1744 - accuracy: 0.9370 - val_loss: 0.3174 - val_accuracy: 0.9043\n",
      "Epoch 281/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1727 - accuracy: 0.9387 - val_loss: 0.3085 - val_accuracy: 0.9070\n",
      "Epoch 282/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1767 - accuracy: 0.9375 - val_loss: 0.3078 - val_accuracy: 0.9066\n",
      "Epoch 283/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1768 - accuracy: 0.9360 - val_loss: 0.3063 - val_accuracy: 0.9085\n",
      "Epoch 284/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1786 - accuracy: 0.9361 - val_loss: 0.3220 - val_accuracy: 0.9064\n",
      "Epoch 285/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1774 - accuracy: 0.9336 - val_loss: 0.3132 - val_accuracy: 0.9073\n",
      "Epoch 286/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1806 - accuracy: 0.9326 - val_loss: 0.3114 - val_accuracy: 0.9090\n",
      "Epoch 287/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1860 - accuracy: 0.9351 - val_loss: 0.3054 - val_accuracy: 0.9101\n",
      "Epoch 288/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1721 - accuracy: 0.9383 - val_loss: 0.3027 - val_accuracy: 0.9100\n",
      "Epoch 289/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1742 - accuracy: 0.9362 - val_loss: 0.3181 - val_accuracy: 0.9081\n",
      "Epoch 290/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1781 - accuracy: 0.9383 - val_loss: 0.3232 - val_accuracy: 0.9053\n",
      "Epoch 291/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1735 - accuracy: 0.9381 - val_loss: 0.3206 - val_accuracy: 0.9041\n",
      "Epoch 292/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1718 - accuracy: 0.9373 - val_loss: 0.3098 - val_accuracy: 0.9101\n",
      "Epoch 293/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1829 - accuracy: 0.9352 - val_loss: 0.3207 - val_accuracy: 0.9083\n",
      "Epoch 294/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1839 - accuracy: 0.9323 - val_loss: 0.3082 - val_accuracy: 0.9107\n",
      "Epoch 295/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1733 - accuracy: 0.9397 - val_loss: 0.3160 - val_accuracy: 0.9109\n",
      "Epoch 296/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1794 - accuracy: 0.9391 - val_loss: 0.3082 - val_accuracy: 0.9130\n",
      "Epoch 297/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1822 - accuracy: 0.9325 - val_loss: 0.3322 - val_accuracy: 0.9049\n",
      "Epoch 298/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1804 - accuracy: 0.9348 - val_loss: 0.3159 - val_accuracy: 0.9103\n",
      "Epoch 299/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1803 - accuracy: 0.9381 - val_loss: 0.3088 - val_accuracy: 0.9126\n",
      "Epoch 300/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1725 - accuracy: 0.9392 - val_loss: 0.3166 - val_accuracy: 0.9113\n",
      "Epoch 301/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1778 - accuracy: 0.9372 - val_loss: 0.3198 - val_accuracy: 0.9113\n",
      "Epoch 302/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1700 - accuracy: 0.9379 - val_loss: 0.3208 - val_accuracy: 0.9081\n",
      "Epoch 303/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1745 - accuracy: 0.9383 - val_loss: 0.3109 - val_accuracy: 0.9133\n",
      "Epoch 304/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1747 - accuracy: 0.9350 - val_loss: 0.3145 - val_accuracy: 0.9118\n",
      "Epoch 305/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1807 - accuracy: 0.9321 - val_loss: 0.3163 - val_accuracy: 0.9126\n",
      "Epoch 306/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1711 - accuracy: 0.9383 - val_loss: 0.3063 - val_accuracy: 0.9135\n",
      "Epoch 307/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1710 - accuracy: 0.9387 - val_loss: 0.3212 - val_accuracy: 0.9079\n",
      "Epoch 308/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1746 - accuracy: 0.9348 - val_loss: 0.3115 - val_accuracy: 0.9115\n",
      "Epoch 309/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1717 - accuracy: 0.9374 - val_loss: 0.3038 - val_accuracy: 0.9143\n",
      "Epoch 310/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1742 - accuracy: 0.9360 - val_loss: 0.3100 - val_accuracy: 0.9128\n",
      "Epoch 311/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1750 - accuracy: 0.9373 - val_loss: 0.3108 - val_accuracy: 0.9122\n",
      "Epoch 312/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1794 - accuracy: 0.9370 - val_loss: 0.3064 - val_accuracy: 0.9124\n",
      "Epoch 313/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1757 - accuracy: 0.9371 - val_loss: 0.3117 - val_accuracy: 0.9130\n",
      "Epoch 314/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1789 - accuracy: 0.9349 - val_loss: 0.3050 - val_accuracy: 0.9150\n",
      "Epoch 315/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1736 - accuracy: 0.9347 - val_loss: 0.3058 - val_accuracy: 0.9128\n",
      "Epoch 316/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1722 - accuracy: 0.9383 - val_loss: 0.3092 - val_accuracy: 0.9130\n",
      "Epoch 317/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1744 - accuracy: 0.9371 - val_loss: 0.3183 - val_accuracy: 0.9113\n",
      "Epoch 318/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1696 - accuracy: 0.9422 - val_loss: 0.3191 - val_accuracy: 0.9094\n",
      "Epoch 319/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1740 - accuracy: 0.9354 - val_loss: 0.3149 - val_accuracy: 0.9101\n",
      "Epoch 320/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1775 - accuracy: 0.9357 - val_loss: 0.3199 - val_accuracy: 0.9073\n",
      "Epoch 321/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1741 - accuracy: 0.9394 - val_loss: 0.3159 - val_accuracy: 0.9088\n",
      "Epoch 322/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1721 - accuracy: 0.9380 - val_loss: 0.3282 - val_accuracy: 0.9040\n",
      "Epoch 323/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1822 - accuracy: 0.9338 - val_loss: 0.3079 - val_accuracy: 0.9124\n",
      "Epoch 324/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1741 - accuracy: 0.9360 - val_loss: 0.3143 - val_accuracy: 0.9101\n",
      "Epoch 325/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1800 - accuracy: 0.9340 - val_loss: 0.3225 - val_accuracy: 0.9085\n",
      "Epoch 326/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1801 - accuracy: 0.9382 - val_loss: 0.3019 - val_accuracy: 0.9124\n",
      "Epoch 327/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1727 - accuracy: 0.9380 - val_loss: 0.3168 - val_accuracy: 0.9107\n",
      "Epoch 328/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1725 - accuracy: 0.9388 - val_loss: 0.3079 - val_accuracy: 0.9100\n",
      "Epoch 329/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1744 - accuracy: 0.9384 - val_loss: 0.3207 - val_accuracy: 0.9092\n",
      "Epoch 330/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1806 - accuracy: 0.9355 - val_loss: 0.3232 - val_accuracy: 0.9083\n",
      "Epoch 331/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1707 - accuracy: 0.9379 - val_loss: 0.3108 - val_accuracy: 0.9122\n",
      "Epoch 332/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1806 - accuracy: 0.9336 - val_loss: 0.3012 - val_accuracy: 0.9135\n",
      "Epoch 333/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1705 - accuracy: 0.9404 - val_loss: 0.2996 - val_accuracy: 0.9139\n",
      "Epoch 334/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1688 - accuracy: 0.9386 - val_loss: 0.3077 - val_accuracy: 0.9143\n",
      "Epoch 335/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1667 - accuracy: 0.9377 - val_loss: 0.3194 - val_accuracy: 0.9096\n",
      "Epoch 336/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1699 - accuracy: 0.9383 - val_loss: 0.3129 - val_accuracy: 0.9115\n",
      "Epoch 337/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1683 - accuracy: 0.9388 - val_loss: 0.3155 - val_accuracy: 0.9109\n",
      "Epoch 338/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1744 - accuracy: 0.9358 - val_loss: 0.3137 - val_accuracy: 0.9107\n",
      "Epoch 339/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1754 - accuracy: 0.9371 - val_loss: 0.3069 - val_accuracy: 0.9124\n",
      "Epoch 340/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1686 - accuracy: 0.9402 - val_loss: 0.3088 - val_accuracy: 0.9118\n",
      "Epoch 341/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1719 - accuracy: 0.9376 - val_loss: 0.3238 - val_accuracy: 0.9094\n",
      "Epoch 342/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1706 - accuracy: 0.9382 - val_loss: 0.3086 - val_accuracy: 0.9115\n",
      "Epoch 343/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1683 - accuracy: 0.9407 - val_loss: 0.3174 - val_accuracy: 0.9120\n",
      "Epoch 344/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1687 - accuracy: 0.9388 - val_loss: 0.3133 - val_accuracy: 0.9111\n",
      "Epoch 345/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1759 - accuracy: 0.9373 - val_loss: 0.2982 - val_accuracy: 0.9152\n",
      "Epoch 346/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1797 - accuracy: 0.9344 - val_loss: 0.3173 - val_accuracy: 0.9133\n",
      "Epoch 347/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1757 - accuracy: 0.9383 - val_loss: 0.3056 - val_accuracy: 0.9158\n",
      "Epoch 348/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1780 - accuracy: 0.9342 - val_loss: 0.3011 - val_accuracy: 0.9175\n",
      "Epoch 349/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1697 - accuracy: 0.9413 - val_loss: 0.3062 - val_accuracy: 0.9128\n",
      "Epoch 350/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1747 - accuracy: 0.9355 - val_loss: 0.3034 - val_accuracy: 0.9150\n",
      "Epoch 351/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1761 - accuracy: 0.9373 - val_loss: 0.3030 - val_accuracy: 0.9122\n",
      "Epoch 352/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1713 - accuracy: 0.9375 - val_loss: 0.3065 - val_accuracy: 0.9122\n",
      "Epoch 353/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1720 - accuracy: 0.9390 - val_loss: 0.3090 - val_accuracy: 0.9109\n",
      "Epoch 354/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1768 - accuracy: 0.9359 - val_loss: 0.2967 - val_accuracy: 0.9173\n",
      "Epoch 355/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1702 - accuracy: 0.9383 - val_loss: 0.3089 - val_accuracy: 0.9128\n",
      "Epoch 356/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1671 - accuracy: 0.9410 - val_loss: 0.3174 - val_accuracy: 0.9105\n",
      "Epoch 357/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1719 - accuracy: 0.9373 - val_loss: 0.3011 - val_accuracy: 0.9150\n",
      "Epoch 358/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1685 - accuracy: 0.9403 - val_loss: 0.3024 - val_accuracy: 0.9158\n",
      "Epoch 359/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1730 - accuracy: 0.9384 - val_loss: 0.3134 - val_accuracy: 0.9124\n",
      "Epoch 360/500\n",
      "10821/10821 [==============================] - 0s 14us/sample - loss: 0.1726 - accuracy: 0.9374 - val_loss: 0.3087 - val_accuracy: 0.9116\n",
      "Epoch 361/500\n",
      "10821/10821 [==============================] - 0s 14us/sample - loss: 0.1696 - accuracy: 0.9389 - val_loss: 0.3225 - val_accuracy: 0.9113\n",
      "Epoch 362/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1703 - accuracy: 0.9387 - val_loss: 0.3036 - val_accuracy: 0.9131\n",
      "Epoch 363/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1749 - accuracy: 0.9395 - val_loss: 0.3218 - val_accuracy: 0.9083\n",
      "Epoch 364/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1785 - accuracy: 0.9364 - val_loss: 0.3145 - val_accuracy: 0.9120\n",
      "Epoch 365/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1739 - accuracy: 0.9379 - val_loss: 0.3232 - val_accuracy: 0.9070\n",
      "Epoch 366/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1746 - accuracy: 0.9367 - val_loss: 0.3173 - val_accuracy: 0.9126\n",
      "Epoch 367/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1716 - accuracy: 0.9371 - val_loss: 0.3100 - val_accuracy: 0.9094\n",
      "Epoch 368/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1703 - accuracy: 0.9379 - val_loss: 0.3258 - val_accuracy: 0.9081\n",
      "Epoch 369/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1667 - accuracy: 0.9409 - val_loss: 0.3197 - val_accuracy: 0.9116\n",
      "Epoch 370/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1716 - accuracy: 0.9380 - val_loss: 0.3132 - val_accuracy: 0.9111\n",
      "Epoch 371/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1697 - accuracy: 0.9378 - val_loss: 0.3120 - val_accuracy: 0.9150\n",
      "Epoch 372/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1655 - accuracy: 0.9404 - val_loss: 0.3103 - val_accuracy: 0.9150\n",
      "Epoch 373/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1698 - accuracy: 0.9383 - val_loss: 0.3284 - val_accuracy: 0.9128\n",
      "Epoch 374/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1763 - accuracy: 0.9369 - val_loss: 0.3276 - val_accuracy: 0.9107\n",
      "Epoch 375/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1673 - accuracy: 0.9404 - val_loss: 0.3263 - val_accuracy: 0.9141\n",
      "Epoch 376/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1775 - accuracy: 0.9364 - val_loss: 0.3194 - val_accuracy: 0.9152\n",
      "Epoch 377/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1715 - accuracy: 0.9378 - val_loss: 0.3305 - val_accuracy: 0.9107\n",
      "Epoch 378/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1745 - accuracy: 0.9369 - val_loss: 0.3195 - val_accuracy: 0.9128\n",
      "Epoch 379/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1695 - accuracy: 0.9407 - val_loss: 0.3217 - val_accuracy: 0.9126\n",
      "Epoch 380/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1715 - accuracy: 0.9395 - val_loss: 0.3082 - val_accuracy: 0.9135\n",
      "Epoch 381/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1656 - accuracy: 0.9415 - val_loss: 0.3163 - val_accuracy: 0.9143\n",
      "Epoch 382/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1672 - accuracy: 0.9393 - val_loss: 0.3068 - val_accuracy: 0.9167\n",
      "Epoch 383/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1753 - accuracy: 0.9348 - val_loss: 0.3134 - val_accuracy: 0.9101\n",
      "Epoch 384/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1654 - accuracy: 0.9412 - val_loss: 0.3179 - val_accuracy: 0.9100\n",
      "Epoch 385/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1675 - accuracy: 0.9409 - val_loss: 0.3268 - val_accuracy: 0.9086\n",
      "Epoch 386/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1694 - accuracy: 0.9385 - val_loss: 0.3013 - val_accuracy: 0.9145\n",
      "Epoch 387/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1651 - accuracy: 0.9406 - val_loss: 0.3136 - val_accuracy: 0.9098\n",
      "Epoch 388/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1689 - accuracy: 0.9387 - val_loss: 0.3120 - val_accuracy: 0.9158\n",
      "Epoch 389/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1731 - accuracy: 0.9357 - val_loss: 0.3068 - val_accuracy: 0.9126\n",
      "Epoch 390/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1740 - accuracy: 0.9366 - val_loss: 0.3099 - val_accuracy: 0.9143\n",
      "Epoch 391/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1704 - accuracy: 0.9402 - val_loss: 0.3222 - val_accuracy: 0.9124\n",
      "Epoch 392/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1693 - accuracy: 0.9409 - val_loss: 0.3233 - val_accuracy: 0.9107\n",
      "Epoch 393/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1684 - accuracy: 0.9396 - val_loss: 0.3244 - val_accuracy: 0.9107\n",
      "Epoch 394/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1674 - accuracy: 0.9411 - val_loss: 0.3290 - val_accuracy: 0.9090\n",
      "Epoch 395/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1719 - accuracy: 0.9379 - val_loss: 0.3243 - val_accuracy: 0.9098\n",
      "Epoch 396/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1699 - accuracy: 0.9382 - val_loss: 0.3060 - val_accuracy: 0.9147\n",
      "Epoch 397/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1663 - accuracy: 0.9399 - val_loss: 0.3200 - val_accuracy: 0.9120\n",
      "Epoch 398/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1710 - accuracy: 0.9385 - val_loss: 0.3206 - val_accuracy: 0.9118\n",
      "Epoch 399/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1749 - accuracy: 0.9348 - val_loss: 0.3192 - val_accuracy: 0.9139\n",
      "Epoch 400/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1723 - accuracy: 0.9364 - val_loss: 0.3246 - val_accuracy: 0.9135\n",
      "Epoch 401/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1665 - accuracy: 0.9420 - val_loss: 0.3158 - val_accuracy: 0.9130\n",
      "Epoch 402/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1695 - accuracy: 0.9386 - val_loss: 0.3155 - val_accuracy: 0.9158\n",
      "Epoch 403/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1644 - accuracy: 0.9431 - val_loss: 0.3370 - val_accuracy: 0.9085\n",
      "Epoch 404/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1632 - accuracy: 0.9420 - val_loss: 0.3200 - val_accuracy: 0.9130\n",
      "Epoch 405/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1640 - accuracy: 0.9440 - val_loss: 0.3235 - val_accuracy: 0.9135\n",
      "Epoch 406/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1772 - accuracy: 0.9341 - val_loss: 0.3255 - val_accuracy: 0.9118\n",
      "Epoch 407/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1713 - accuracy: 0.9397 - val_loss: 0.3245 - val_accuracy: 0.9098\n",
      "Epoch 408/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1768 - accuracy: 0.9359 - val_loss: 0.3170 - val_accuracy: 0.9131\n",
      "Epoch 409/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1729 - accuracy: 0.9393 - val_loss: 0.3150 - val_accuracy: 0.9152\n",
      "Epoch 410/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1675 - accuracy: 0.9409 - val_loss: 0.3223 - val_accuracy: 0.9156\n",
      "Epoch 411/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1644 - accuracy: 0.9429 - val_loss: 0.3330 - val_accuracy: 0.9133\n",
      "Epoch 412/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1716 - accuracy: 0.9380 - val_loss: 0.3217 - val_accuracy: 0.9145\n",
      "Epoch 413/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1663 - accuracy: 0.9394 - val_loss: 0.3252 - val_accuracy: 0.9128\n",
      "Epoch 414/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1662 - accuracy: 0.9411 - val_loss: 0.3210 - val_accuracy: 0.9150\n",
      "Epoch 415/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1649 - accuracy: 0.9402 - val_loss: 0.3289 - val_accuracy: 0.9131\n",
      "Epoch 416/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1689 - accuracy: 0.9384 - val_loss: 0.3045 - val_accuracy: 0.9199\n",
      "Epoch 417/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1719 - accuracy: 0.9377 - val_loss: 0.3194 - val_accuracy: 0.9160\n",
      "Epoch 418/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1657 - accuracy: 0.9414 - val_loss: 0.3189 - val_accuracy: 0.9152\n",
      "Epoch 419/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1717 - accuracy: 0.9380 - val_loss: 0.3113 - val_accuracy: 0.9160\n",
      "Epoch 420/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1666 - accuracy: 0.9402 - val_loss: 0.3047 - val_accuracy: 0.9192\n",
      "Epoch 421/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1687 - accuracy: 0.9384 - val_loss: 0.3109 - val_accuracy: 0.9177\n",
      "Epoch 422/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1651 - accuracy: 0.9419 - val_loss: 0.3220 - val_accuracy: 0.9131\n",
      "Epoch 423/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1642 - accuracy: 0.9412 - val_loss: 0.3178 - val_accuracy: 0.9171\n",
      "Epoch 424/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1645 - accuracy: 0.9415 - val_loss: 0.3147 - val_accuracy: 0.9173\n",
      "Epoch 425/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1646 - accuracy: 0.9397 - val_loss: 0.3275 - val_accuracy: 0.9101\n",
      "Epoch 426/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1636 - accuracy: 0.9403 - val_loss: 0.3291 - val_accuracy: 0.9124\n",
      "Epoch 427/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1685 - accuracy: 0.9378 - val_loss: 0.3326 - val_accuracy: 0.9107\n",
      "Epoch 428/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1611 - accuracy: 0.9455 - val_loss: 0.3336 - val_accuracy: 0.9100\n",
      "Epoch 429/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1677 - accuracy: 0.9378 - val_loss: 0.3228 - val_accuracy: 0.9147\n",
      "Epoch 430/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1730 - accuracy: 0.9372 - val_loss: 0.3115 - val_accuracy: 0.9171\n",
      "Epoch 431/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1664 - accuracy: 0.9414 - val_loss: 0.3106 - val_accuracy: 0.9203\n",
      "Epoch 432/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1686 - accuracy: 0.9429 - val_loss: 0.3134 - val_accuracy: 0.9188\n",
      "Epoch 433/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1667 - accuracy: 0.9413 - val_loss: 0.3234 - val_accuracy: 0.9145\n",
      "Epoch 434/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1690 - accuracy: 0.9411 - val_loss: 0.3226 - val_accuracy: 0.9111\n",
      "Epoch 435/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1697 - accuracy: 0.9379 - val_loss: 0.3167 - val_accuracy: 0.9154\n",
      "Epoch 436/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1636 - accuracy: 0.9408 - val_loss: 0.3156 - val_accuracy: 0.9150\n",
      "Epoch 437/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1642 - accuracy: 0.9391 - val_loss: 0.3182 - val_accuracy: 0.9130\n",
      "Epoch 438/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1650 - accuracy: 0.9427 - val_loss: 0.3169 - val_accuracy: 0.9163\n",
      "Epoch 439/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1600 - accuracy: 0.9433 - val_loss: 0.3287 - val_accuracy: 0.9120\n",
      "Epoch 440/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1643 - accuracy: 0.9389 - val_loss: 0.3199 - val_accuracy: 0.9139\n",
      "Epoch 441/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1644 - accuracy: 0.9391 - val_loss: 0.3189 - val_accuracy: 0.9150\n",
      "Epoch 442/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1719 - accuracy: 0.9378 - val_loss: 0.3337 - val_accuracy: 0.9105\n",
      "Epoch 443/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1666 - accuracy: 0.9431 - val_loss: 0.3180 - val_accuracy: 0.9141\n",
      "Epoch 444/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1719 - accuracy: 0.9382 - val_loss: 0.3293 - val_accuracy: 0.9113\n",
      "Epoch 445/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1686 - accuracy: 0.9385 - val_loss: 0.3197 - val_accuracy: 0.9158\n",
      "Epoch 446/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1596 - accuracy: 0.9416 - val_loss: 0.3209 - val_accuracy: 0.9137\n",
      "Epoch 447/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1645 - accuracy: 0.9420 - val_loss: 0.3162 - val_accuracy: 0.9195\n",
      "Epoch 448/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1640 - accuracy: 0.9401 - val_loss: 0.3091 - val_accuracy: 0.9141\n",
      "Epoch 449/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1608 - accuracy: 0.9433 - val_loss: 0.3145 - val_accuracy: 0.9141\n",
      "Epoch 450/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1610 - accuracy: 0.9421 - val_loss: 0.3144 - val_accuracy: 0.9158\n",
      "Epoch 451/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1636 - accuracy: 0.9413 - val_loss: 0.3171 - val_accuracy: 0.9122\n",
      "Epoch 452/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1636 - accuracy: 0.9409 - val_loss: 0.3297 - val_accuracy: 0.9103\n",
      "Epoch 453/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1712 - accuracy: 0.9393 - val_loss: 0.3108 - val_accuracy: 0.9133\n",
      "Epoch 454/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1590 - accuracy: 0.9451 - val_loss: 0.3136 - val_accuracy: 0.9156\n",
      "Epoch 455/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1658 - accuracy: 0.9420 - val_loss: 0.3164 - val_accuracy: 0.9152\n",
      "Epoch 456/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1616 - accuracy: 0.9415 - val_loss: 0.3116 - val_accuracy: 0.9162\n",
      "Epoch 457/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1582 - accuracy: 0.9456 - val_loss: 0.3206 - val_accuracy: 0.9178\n",
      "Epoch 458/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1641 - accuracy: 0.9414 - val_loss: 0.3158 - val_accuracy: 0.9182\n",
      "Epoch 459/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1739 - accuracy: 0.9384 - val_loss: 0.3251 - val_accuracy: 0.9118\n",
      "Epoch 460/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1653 - accuracy: 0.9427 - val_loss: 0.3194 - val_accuracy: 0.9107\n",
      "Epoch 461/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1635 - accuracy: 0.9432 - val_loss: 0.3059 - val_accuracy: 0.9128\n",
      "Epoch 462/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1697 - accuracy: 0.9369 - val_loss: 0.3188 - val_accuracy: 0.9116\n",
      "Epoch 463/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1650 - accuracy: 0.9418 - val_loss: 0.3026 - val_accuracy: 0.9186\n",
      "Epoch 464/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1623 - accuracy: 0.9427 - val_loss: 0.3137 - val_accuracy: 0.9135\n",
      "Epoch 465/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1629 - accuracy: 0.9418 - val_loss: 0.3081 - val_accuracy: 0.9141\n",
      "Epoch 466/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1590 - accuracy: 0.9423 - val_loss: 0.3200 - val_accuracy: 0.9152\n",
      "Epoch 467/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1579 - accuracy: 0.9437 - val_loss: 0.3241 - val_accuracy: 0.9130\n",
      "Epoch 468/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1594 - accuracy: 0.9445 - val_loss: 0.3199 - val_accuracy: 0.9137\n",
      "Epoch 469/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1564 - accuracy: 0.9446 - val_loss: 0.3252 - val_accuracy: 0.9130\n",
      "Epoch 470/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1735 - accuracy: 0.9398 - val_loss: 0.3251 - val_accuracy: 0.9137\n",
      "Epoch 471/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1678 - accuracy: 0.9404 - val_loss: 0.3261 - val_accuracy: 0.9124\n",
      "Epoch 472/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1607 - accuracy: 0.9434 - val_loss: 0.3363 - val_accuracy: 0.9160\n",
      "Epoch 473/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1565 - accuracy: 0.9461 - val_loss: 0.3213 - val_accuracy: 0.9158\n",
      "Epoch 474/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1599 - accuracy: 0.9431 - val_loss: 0.3120 - val_accuracy: 0.9175\n",
      "Epoch 475/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1604 - accuracy: 0.9416 - val_loss: 0.3229 - val_accuracy: 0.9152\n",
      "Epoch 476/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1567 - accuracy: 0.9455 - val_loss: 0.3244 - val_accuracy: 0.9167\n",
      "Epoch 477/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1597 - accuracy: 0.9455 - val_loss: 0.3176 - val_accuracy: 0.9171\n",
      "Epoch 478/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1646 - accuracy: 0.9414 - val_loss: 0.3328 - val_accuracy: 0.9139\n",
      "Epoch 479/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1657 - accuracy: 0.9409 - val_loss: 0.3173 - val_accuracy: 0.9169\n",
      "Epoch 480/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1611 - accuracy: 0.9427 - val_loss: 0.3174 - val_accuracy: 0.9175\n",
      "Epoch 481/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1666 - accuracy: 0.9397 - val_loss: 0.3179 - val_accuracy: 0.9197\n",
      "Epoch 482/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1639 - accuracy: 0.9431 - val_loss: 0.3249 - val_accuracy: 0.9165\n",
      "Epoch 483/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1632 - accuracy: 0.9414 - val_loss: 0.3326 - val_accuracy: 0.9137\n",
      "Epoch 484/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1623 - accuracy: 0.9418 - val_loss: 0.3217 - val_accuracy: 0.9167\n",
      "Epoch 485/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1687 - accuracy: 0.9402 - val_loss: 0.3254 - val_accuracy: 0.9147\n",
      "Epoch 486/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1569 - accuracy: 0.9432 - val_loss: 0.3295 - val_accuracy: 0.9143\n",
      "Epoch 487/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1616 - accuracy: 0.9432 - val_loss: 0.3253 - val_accuracy: 0.9156\n",
      "Epoch 488/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1583 - accuracy: 0.9426 - val_loss: 0.3256 - val_accuracy: 0.9175\n",
      "Epoch 489/500\n",
      "10821/10821 [==============================] - 0s 12us/sample - loss: 0.1685 - accuracy: 0.9378 - val_loss: 0.3157 - val_accuracy: 0.9162\n",
      "Epoch 490/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1596 - accuracy: 0.9427 - val_loss: 0.3146 - val_accuracy: 0.9182\n",
      "Epoch 491/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1621 - accuracy: 0.9426 - val_loss: 0.3272 - val_accuracy: 0.9154\n",
      "Epoch 492/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1647 - accuracy: 0.9416 - val_loss: 0.3167 - val_accuracy: 0.9152\n",
      "Epoch 493/500\n",
      "10821/10821 [==============================] - 0s 10us/sample - loss: 0.1599 - accuracy: 0.9413 - val_loss: 0.3208 - val_accuracy: 0.9158\n",
      "Epoch 494/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1654 - accuracy: 0.9398 - val_loss: 0.3307 - val_accuracy: 0.9150\n",
      "Epoch 495/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1588 - accuracy: 0.9407 - val_loss: 0.3335 - val_accuracy: 0.9131\n",
      "Epoch 496/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1644 - accuracy: 0.9418 - val_loss: 0.3203 - val_accuracy: 0.9160\n",
      "Epoch 497/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1549 - accuracy: 0.9440 - val_loss: 0.3178 - val_accuracy: 0.9175\n",
      "Epoch 498/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1619 - accuracy: 0.9419 - val_loss: 0.3178 - val_accuracy: 0.9180\n",
      "Epoch 499/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1625 - accuracy: 0.9428 - val_loss: 0.3341 - val_accuracy: 0.9126\n",
      "Epoch 500/500\n",
      "10821/10821 [==============================] - 0s 11us/sample - loss: 0.1685 - accuracy: 0.9390 - val_loss: 0.3191 - val_accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a545d2cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          validation_data = (X_Test, Y_Test),\n",
    "          epochs = 500,\n",
    "          batch_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"house_loan_90_percent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting roc auc curve to analyze the performance of model\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#predict the outcomes on Test data:\n",
    "y_test_predicted = model.predict(X_Test)\n",
    "\n",
    "fpr , tpr , thresholds = roc_curve ( Y_Test , y_test_predicted)\n",
    "\n",
    "\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for the model obtained is:  0.9437900315846757\n"
     ]
    }
   ],
   "source": [
    "#computing auc score\n",
    "auc_score=roc_auc_score(Y_Test,y_test_predicted) \n",
    "\n",
    "print(\"AUC score for the model obtained is: \", auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
